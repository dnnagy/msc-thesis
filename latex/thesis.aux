\relax 
\providecommand\hyper@newdestlabel[2]{}
\catcode \string ``=12
\bbl@cs{beforestart}
\bibstyle{unsrtnat}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\select@language{english} \hypertarget {toc}{}}
\citation{wikipedianeuron}
\citation{DeutschJozsa1992}
\citation{Shor1994}
\citation{Grover1996}
\citation{Tang2019,Ding2019QuantumInspiredSVM,ArrazolaQuantumInspired2019}
\@writefile{toc}{\select@language{english} \contentsline {section}{\numberline {1}Introduction}{9}{section.1}\protected@file@percent }
\@writefile{toc}{\select@language{english} \contentsline {section}{\numberline {2}Quantum Computing with continuous variables}{9}{section.2}\protected@file@percent }
\newlabel{eq:jwtransform}{{6}{10}{Quantum Computing with continuous variables}{equation.2.6}{}}
\newlabel{eq:xidef}{{7}{10}{Quantum Computing with continuous variables}{equation.2.7}{}}
\citation{VAEPaper}
\citation{RLAtariDQN}
\citation{Silver2016AlphaGo}
\@writefile{toc}{\select@language{english} \contentsline {section}{\numberline {3}Machine learning}{11}{section.3}\protected@file@percent }
\newlabel{sec:ml-intro}{{3}{11}{Machine learning}{section.3}{}}
\@writefile{toc}{\select@language{english} \contentsline {subsection}{\numberline {3.1}Supervised Classification and Regression}{12}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\select@language{english} \contentsline {subsubsection}{\numberline {3.1.1}Classification}{12}{subsubsection.3.1.1}\protected@file@percent }
\newlabel{eq:crossentropy}{{18}{13}{Classification}{equation.3.18}{}}
\@writefile{toc}{\select@language{english} \contentsline {subsubsection}{\numberline {3.1.2}Regression}{13}{subsubsection.3.1.2}\protected@file@percent }
\citation{LeCun2015DeepLearning}
\citation{wikipedianeuron}
\@writefile{toc}{\select@language{english} \contentsline {subsection}{\numberline {3.2}Deep Neural Networks and backpropagation}{14}{subsection.3.2}\protected@file@percent }
\newlabel{sec:dnn}{{3.2}{14}{Deep Neural Networks and backpropagation}{subsection.3.2}{}}
\@writefile{lof}{\select@language{english} \contentsline {figure}{\numberline {1}{\ignorespaces neuron from \cite  {wikipedianeuron}}}{14}{figure.1}\protected@file@percent }
\newlabel{fig:neuron}{{1}{14}{neuron from \cite {wikipedianeuron}}{figure.1}{}}
\@writefile{lof}{\select@language{english} \contentsline {figure}{\numberline {2}{\ignorespaces The multilayer perceptron architecture. Green circles are the input features which can be scalar or vector values, the yellow circles represent the weights and biases of the perceptrons of the hidden layers, while the red circle is the output. Data flow is noted with black arrows.}}{15}{figure.2}\protected@file@percent }
\newlabel{fig:MLP}{{2}{15}{The multilayer perceptron architecture. Green circles are the input features which can be scalar or vector values, the yellow circles represent the weights and biases of the perceptrons of the hidden layers, while the red circle is the output. Data flow is noted with black arrows}{figure.2}{}}
\citation{LeCun-CNN}
\citation{SchmidhuberLSTM}
\citation{Transformer}
\citation{BackpropPaper}
\@writefile{lof}{\select@language{english} \contentsline {figure}{\numberline {3}{\ignorespaces The three most frequently used activation functions in deep neural networks. Left: the sigmoid function, middle: rectified linear unit (ReLU), right: leaky ReLU.}}{16}{figure.3}\protected@file@percent }
\newlabel{fig:activations}{{3}{16}{The three most frequently used activation functions in deep neural networks. Left: the sigmoid function, middle: rectified linear unit (ReLU), right: leaky ReLU}{figure.3}{}}
\@writefile{loa}{\select@language{english} \contentsline {algorithm}{\numberline {1}{\ignorespaces Gradient Descent}}{16}{algorithm.1}\protected@file@percent }
\newlabel{algo:gd}{{1}{16}{Deep Neural Networks and backpropagation}{algorithm.1}{}}
\citation{QSVMPaper}
\citation{HHLPaper}
\citation{FeatureHilbertSpaces}
\citation{Peruzzo2014}
\citation{Wei2020-QCHEM,VQE-HARTREE-FOCK,Kandala2017-VQE-QCHEM,PhysRevX-VQE-QCHEM}
\newlabel{eq:softmax}{{27}{17}{Deep Neural Networks and backpropagation}{equation.3.27}{}}
\@writefile{toc}{\select@language{english} \contentsline {section}{\numberline {4}Quantum Machine Learning}{17}{section.4}\protected@file@percent }
\@writefile{lof}{\select@language{english} \contentsline {figure}{\numberline {4}{\ignorespaces VQC-optimization.}}{17}{figure.4}\protected@file@percent }
\newlabel{fig:VQC-optimization}{{4}{17}{VQC-optimization}{figure.4}{}}
\citation{Zhu2019}
\citation{Kingma2015AdamAM}
\citation{CVQNNLLoyd}
\citation{AnalyticGradientsSchuld}
\@writefile{toc}{\select@language{english} \contentsline {subsection}{\numberline {4.1}Variational Quantum Eigensolver}{18}{subsection.4.1}\protected@file@percent }
\newlabel{sec:vqe}{{4.1}{18}{Variational Quantum Eigensolver}{subsection.4.1}{}}
\@writefile{loa}{\select@language{english} \contentsline {algorithm}{\numberline {2}{\ignorespaces K-shot VQE}}{18}{algorithm.2}\protected@file@percent }
\newlabel{algo:vqe}{{2}{18}{Variational Quantum Eigensolver}{algorithm.2}{}}
\@writefile{toc}{\select@language{english} \contentsline {subsection}{\numberline {4.2}Quantum Neural Networks}{18}{subsection.4.2}\protected@file@percent }
\newlabel{sec:qnn}{{4.2}{18}{Quantum Neural Networks}{subsection.4.2}{}}
\citation{Killoran2019strawberryfields,ApplicationsOfStrawberryFields}
\citation{abadi2016tensorflow}
\citation{scikit-learn}
\citation{CVQNNLLoyd}
\@writefile{toc}{\select@language{english} \contentsline {subsection}{\numberline {4.3}Calculating the gradients of the parameters}{19}{subsection.4.3}\protected@file@percent }
\newlabel{sec:qgrad}{{4.3}{19}{Calculating the gradients of the parameters}{subsection.4.3}{}}
\@writefile{toc}{\select@language{english} \contentsline {section}{\numberline {5}Results}{19}{section.5}\protected@file@percent }
\@writefile{toc}{\select@language{english} \contentsline {subsection}{\numberline {5.1}Classification}{19}{subsection.5.1}\protected@file@percent }
\newlabel{sec:classification-results}{{5.1}{19}{Classification}{subsection.5.1}{}}
\@writefile{lof}{\select@language{english} \contentsline {figure}{\numberline {5}{\ignorespaces Ansatz circuit used in the classification task with the first layer.}}{20}{figure.5}\protected@file@percent }
\newlabel{fig:single_layer_classification}{{5}{20}{Ansatz circuit used in the classification task with the first layer}{figure.5}{}}
\@writefile{lof}{\select@language{english} \contentsline {figure}{\numberline {6}{\ignorespaces leiras}}{21}{figure.6}\protected@file@percent }
\newlabel{fig:classification_results}{{6}{21}{leiras}{figure.6}{}}
\@writefile{lof}{\select@language{english} \contentsline {figure}{\numberline {7}{\ignorespaces }}{21}{figure.7}\protected@file@percent }
\newlabel{fig:single_layer_regression}{{7}{21}{}{figure.7}{}}
\citation{CVQNNLLoyd}
\citation{CVQNNLLoyd}
\@writefile{toc}{\select@language{english} \contentsline {subsection}{\numberline {5.2}Regression}{22}{subsection.5.2}\protected@file@percent }
\newlabel{sec:regression-results}{{5.2}{22}{Regression}{subsection.5.2}{}}
\newlabel{eq:regression-output}{{38}{22}{Regression}{equation.5.38}{}}
\@writefile{lof}{\select@language{english} \contentsline {figure}{\numberline {8}{\ignorespaces Ansatz circuit for the regression task. We use displacement encoding and six consecutive identical layers with a homodyne measurement at the end.}}{23}{figure.8}\protected@file@percent }
\newlabel{fig:BasicTwoModeRegressor}{{8}{23}{Ansatz circuit for the regression task. We use displacement encoding and six consecutive identical layers with a homodyne measurement at the end}{figure.8}{}}
\@writefile{lof}{\select@language{english} \contentsline {figure}{\numberline {9}{\ignorespaces Comparison of the regression circuit performance on the test set with different number of layers.}}{23}{figure.9}\protected@file@percent }
\newlabel{fig:tanh_layer_search}{{9}{23}{Comparison of the regression circuit performance on the test set with different number of layers}{figure.9}{}}
\@writefile{lot}{\select@language{english} \contentsline {table}{\numberline {1}{\ignorespaces Hyperparameters of the regression simulations}}{23}{table.1}\protected@file@percent }
\newlabel{tab:hyperparams-regression}{{1}{23}{Hyperparameters of the regression simulations}{table.1}{}}
\citation{BoseHubbardOriginal,ColdAtomtHubbard}
\citation{SuperfluidityMottTransition,Greiner2002}
\@writefile{lof}{\select@language{english} \contentsline {figure}{\numberline {10}{\ignorespaces The top row shows how the regression circuits perform on the test set. The figures show loss curves with different number of shots for the $\qopname  \relax o{tanh}$ function (a) and the I-V curve (b). The bottom rows show inference tests with $1000$ shots both for the $\qopname  \relax o{tanh}$ function (c) as well as the I-V curve (d). All simulations were run with $\alpha =0.001$ and mini-batch size $4$.\\ \leavevmode {\color  {Aquamarine}\textbf  {[Dani: Change tanh-results-bs=16-lr=0\_001-s1000.pdf to tanh-results-bs=\leavevmode {\color  {red}4}-lr=0\_001-s1000.pdf]}}\\ \leavevmode {\color  {Aquamarine}\textbf  {[Dani: increase tick size on inference plots]}} }}{24}{figure.10}\protected@file@percent }
\newlabel{fig:regression_results}{{10}{24}{The top row shows how the regression circuits perform on the test set. The figures show loss curves with different number of shots for the $\tanh $ function (a) and the I-V curve (b). The bottom rows show inference tests with $1000$ shots both for the $\tanh $ function (c) as well as the I-V curve (d). All simulations were run with $\alpha =0.001$ and mini-batch size $4$.\\ \nd {Change tanh-results-bs=16-lr=0\_001-s1000.pdf to tanh-results-bs=\red {4}-lr=0\_001-s1000.pdf}\\ \nd {increase tick size on inference plots}}{figure.10}{}}
\@writefile{toc}{\select@language{english} \contentsline {subsection}{\numberline {5.3}CV-VQE for the Bose-Hubbard model}{24}{subsection.5.3}\protected@file@percent }
\newlabel{sec:bh-vqe-results}{{5.3}{24}{CV-VQE for the Bose-Hubbard model}{subsection.5.3}{}}
\newlabel{eq:bhhamiltonian}{{39}{25}{CV-VQE for the Bose-Hubbard model}{equation.5.39}{}}
\@writefile{toc}{\select@language{english} \contentsline {subsubsection}{\numberline {5.3.1}Solving the model by exact diagonalization}{25}{subsubsection.5.3.1}\protected@file@percent }
\citation{Wei2020-QCHEM,VQE-HARTREE-FOCK,Kandala2017-VQE-QCHEM,PhysRevX-VQE-QCHEM}
\@writefile{lof}{\select@language{english} \contentsline {figure}{\numberline {11}{\ignorespaces (a) Visual representation of a sparse Hamiltonian matrix $H_{jj'}$ for a Bose-Hubbard model with $\qopname  \relax o{dim}(\mathcal  H)=35$. Darker points show the non-zero elements in the matrix (b) Numerical solutions of the ground-state energy for different $U$ and $t$ values.}}{26}{figure.11}\protected@file@percent }
\newlabel{fig:exactdiagonalization}{{11}{26}{(a) Visual representation of a sparse Hamiltonian matrix $H_{jj'}$ for a Bose-Hubbard model with $\dim (\mathcal H)=35$. Darker points show the non-zero elements in the matrix (b) Numerical solutions of the ground-state energy for different $U$ and $t$ values}{figure.11}{}}
\@writefile{toc}{\select@language{english} \contentsline {subsubsection}{\numberline {5.3.2}Variational solutions}{26}{subsubsection.5.3.2}\protected@file@percent }
\@writefile{lof}{\select@language{english} \contentsline {figure}{\numberline {12}{\ignorespaces Illustration of a variational ansatz circuit with its first layer. Initially, each of the four qumodes contain a single photon. The layer is built up from Kerr-gates, CrossKerr gates and Beamsplitters, which are passive optical gates, so the total number of photons is preserved.}}{26}{figure.12}\protected@file@percent }
\newlabel{fig:single_layer_vqe}{{12}{26}{Illustration of a variational ansatz circuit with its first layer. Initially, each of the four qumodes contain a single photon. The layer is built up from Kerr-gates, CrossKerr gates and Beamsplitters, which are passive optical gates, so the total number of photons is preserved}{figure.12}{}}
\@writefile{lof}{\select@language{english} \contentsline {figure}{\numberline {13}{\ignorespaces }}{27}{figure.13}\protected@file@percent }
\newlabel{fig:single_layer_vqe}{{13}{27}{}{figure.13}{}}
\bibdata{references}
\bibcite{wikipedianeuron}{{1}{}{{wik}}{{}}}
\bibcite{DeutschJozsa1992}{{2}{1992}{{Deutsch and Jozsa}}{{}}}
\bibcite{Shor1994}{{3}{}{{Shor}}{{}}}
\@writefile{lof}{\select@language{english} \contentsline {figure}{\numberline {14}{\ignorespaces caption}}{28}{figure.14}\protected@file@percent }
\@writefile{toc}{\select@language{english} \contentsline {section}{\numberline {6}Conclusion and future work}{28}{section.6}\protected@file@percent }
\bibcite{Grover1996}{{4}{1996}{{Grover}}{{}}}
\bibcite{Tang2019}{{5}{2019}{{Tang}}{{}}}
\bibcite{Ding2019QuantumInspiredSVM}{{6}{2019}{{{Ding} et~al.}}{{{Ding}, {Bao}, and {Huang}}}}
\bibcite{ArrazolaQuantumInspired2019}{{7}{2019}{{{Arrazola} et~al.}}{{{Arrazola}, {Delgado}, {Bardhan}, and {Lloyd}}}}
\bibcite{VAEPaper}{{8}{2013}{{{Kingma} and {Welling}}}{{}}}
\bibcite{RLAtariDQN}{{9}{2013}{{{Mnih} et~al.}}{{{Mnih}, {Kavukcuoglu}, {Silver}, {Graves}, {Antonoglou}, {Wierstra}, and {Riedmiller}}}}
\bibcite{Silver2016AlphaGo}{{10}{2016}{{Silver et~al.}}{{Silver, Huang, Maddison, Guez, Sifre, van~den Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot, Dieleman, Grewe, Nham, Kalchbrenner, Sutskever, Lillicrap, Leach, Kavukcuoglu, Graepel, and Hassabis}}}
\bibcite{LeCun2015DeepLearning}{{11}{2015}{{LeCun et~al.}}{{LeCun, Bengio, and Hinton}}}
\bibcite{LeCun-CNN}{{12}{1989}{{LeCun et~al.}}{{LeCun, Boser, Denker, Henderson, Howard, Hubbard, and Jackel}}}
\bibcite{SchmidhuberLSTM}{{13}{1997}{{Hochreiter and Schmidhuber}}{{}}}
\bibcite{Transformer}{{14}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{BackpropPaper}{{15}{1986}{{Rumelhart et~al.}}{{Rumelhart, Hinton, and Williams}}}
\bibcite{QSVMPaper}{{16}{2014}{{Rebentrost et~al.}}{{Rebentrost, Mohseni, and Lloyd}}}
\bibcite{HHLPaper}{{17}{2009}{{Harrow et~al.}}{{Harrow, Hassidim, and Lloyd}}}
\bibcite{FeatureHilbertSpaces}{{18}{2019}{{Schuld and Killoran}}{{}}}
\bibcite{Peruzzo2014}{{19}{2014}{{Peruzzo et~al.}}{{Peruzzo, McClean, Shadbolt, Yung, Zhou, Love, Aspuru-Guzik, and O'Brien}}}
\bibcite{Wei2020-QCHEM}{{20}{2020}{{Wei et~al.}}{{Wei, Li, and Long}}}
\bibcite{VQE-HARTREE-FOCK}{{21}{2020}{{Arute et~al.}}{{Arute, Arya, Babbush, Bacon, Bardin, Barends, Boixo, Broughton, Buckley, Buell, Burkett, Bushnell, Chen, Chen, Chiaro, Collins, Courtney, Demura, Dunsworth, Farhi, Fowler, Foxen, Gidney, Giustina, Graff, Habegger, Harrigan, Ho, Hong, Huang, Huggins, Ioffe, Isakov, Jeffrey, Jiang, Jones, Kafri, Kechedzhi, Kelly, Kim, Klimov, Korotkov, Kostritsa, Landhuis, Laptev, Lindmark, Lucero, Martin, Martinis, McClean, McEwen, Megrant, Mi, Mohseni, Mruczkiewicz, Mutus, Naaman, Neeley, Neill, Neven, Niu, O{\textquoteright }Brien, Ostby, Petukhov, Putterman, Quintana, Roushan, Rubin, Sank, Satzinger, Smelyanskiy, Strain, Sung, Szalay, Takeshita, Vainsencher, White, Wiebe, Yao, Yeh, and Zalcman}}}
\bibcite{Kandala2017-VQE-QCHEM}{{22}{2017}{{Kandala et~al.}}{{Kandala, Mezzacapo, Temme, Takita, Brink, Chow, and Gambetta}}}
\bibcite{PhysRevX-VQE-QCHEM}{{23}{2018}{{Hempel et~al.}}{{Hempel, Maier, Romero, McClean, Monz, Shen, Jurcevic, Lanyon, Love, Babbush, Aspuru-Guzik, Blatt, and Roos}}}
\bibcite{Zhu2019}{{24}{2019}{{Zhu et~al.}}{{Zhu, Linke, Benedetti, Landsman, Nguyen, Alderete, Perdomo-Ortiz, Korda, Garfoot, Brecque, Egan, Perdomo, and Monroe}}}
\bibcite{Kingma2015AdamAM}{{25}{2015}{{Kingma and Ba}}{{}}}
\bibcite{CVQNNLLoyd}{{26}{2019{}}{{Killoran et~al.}}{{Killoran, Bromley, Arrazola, Schuld, Quesada, and Lloyd}}}
\bibcite{AnalyticGradientsSchuld}{{27}{2019}{{Schuld et~al.}}{{Schuld, Bergholm, Gogolin, Izaac, and Killoran}}}
\bibcite{Killoran2019strawberryfields}{{28}{2019{}}{{Killoran et~al.}}{{Killoran, Izaac, Quesada, Bergholm, Amy, and Weedbrook}}}
\bibcite{ApplicationsOfStrawberryFields}{{29}{2020}{{{Bromley} et~al.}}{{{Bromley}, {Arrazola}, {Jahangiri}, {Izaac}, {Quesada}, {Gran}, {Schuld}, {Swinarton}, {Zabaneh}, and {Killoran}}}}
\bibcite{abadi2016tensorflow}{{30}{2016}{{Abadi et~al.}}{{Abadi, Barham, Chen, Chen, Davis, Dean, Devin, Ghemawat, Irving, Isard, et~al.}}}
\bibcite{scikit-learn}{{31}{2011}{{Pedregosa et~al.}}{{Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, and Duchesnay}}}
\bibcite{BoseHubbardOriginal}{{32}{1963}{{Gersch and Knollman}}{{}}}
\bibcite{ColdAtomtHubbard}{{33}{2005}{{{Jaksch} and {Zoller}}}{{}}}
\bibcite{SuperfluidityMottTransition}{{34}{1998}{{Jaksch et~al.}}{{Jaksch, Bruder, Cirac, Gardiner, and Zoller}}}
\bibcite{Greiner2002}{{35}{2002}{{Greiner et~al.}}{{Greiner, Mandel, Esslinger, H\"{a}nsch, and Bloch}}}
\@writefile{toc}{\select@language{english} \contentsline {section}{\numberline {A}Coherent states}{32}{appendix.A}\protected@file@percent }
\newlabel{appendix:coherent}{{A}{32}{Coherent states}{appendix.A}{}}
\@writefile{toc}{\select@language{english} \contentsline {section}{\numberline {B}Mathematical preliminaries}{33}{appendix.B}\protected@file@percent }
\@writefile{toc}{\select@language{english} \contentsline {subsection}{\numberline {B.1}Hilbert spaces}{33}{subsection.B.1}\protected@file@percent }
\@writefile{toc}{\select@language{english} \contentsline {subsection}{\numberline {B.2}Linear operators on Hilbert spaces}{35}{subsection.B.2}\protected@file@percent }
\@writefile{toc}{\select@language{english} \contentsline {subsection}{\numberline {B.3}Hermitian Operators, Unitary Operators, Spectral theorem, Hadamard-lemma}{35}{subsection.B.3}\protected@file@percent }
\@writefile{toc}{\select@language{english} \contentsline {subsection}{\numberline {B.4}Pure and mixed quantum states}{37}{subsection.B.4}\protected@file@percent }
\newlabel{def:densityop}{{19}{38}{}{definition.19}{}}
