\select@language {english} \contentsline {figure}{\numberline {1}{\ignorespaces neuron from \cite {wikipedianeuron}}}{14}{figure.1}%
\select@language {english} \contentsline {figure}{\numberline {2}{\ignorespaces The multilayer perceptron architecture. Green circles are the input features which can be scalar or vector values, the yellow circles represent the weights and biases of the perceptrons of the hidden layers, while the red circle is the output. Data flow is noted with black arrows.}}{15}{figure.2}%
\select@language {english} \contentsline {figure}{\numberline {3}{\ignorespaces The three most frequently used activation functions in deep neural networks. Left: the sigmoid function, middle: rectified linear unit (ReLU), right: leaky ReLU.}}{16}{figure.3}%
\select@language {english} \contentsline {figure}{\numberline {4}{\ignorespaces VQC-optimization.}}{17}{figure.4}%
\select@language {english} \contentsline {figure}{\numberline {5}{\ignorespaces Ansatz circuit used in the classification task with the first layer.}}{20}{figure.5}%
\select@language {english} \contentsline {figure}{\numberline {6}{\ignorespaces leiras}}{21}{figure.6}%
\select@language {english} \contentsline {figure}{\numberline {7}{\ignorespaces }}{21}{figure.7}%
\select@language {english} \contentsline {figure}{\numberline {8}{\ignorespaces Ansatz circuit for the regression task. We use displacement encoding and six consecutive identical layers with a homodyne measurement at the end.}}{23}{figure.8}%
\select@language {english} \contentsline {figure}{\numberline {9}{\ignorespaces Comparison of the regression circuit performance on the test set with different number of layers.}}{23}{figure.9}%
\select@language {english} \contentsline {figure}{\numberline {10}{\ignorespaces The top row shows how the regression circuits perform on the test set. The figures show loss curves with different number of shots for the $\qopname \relax o{tanh}$ function (a) and the I-V curve (b). The bottom rows show inference tests with $1000$ shots both for the $\qopname \relax o{tanh}$ function (c) as well as the I-V curve (d). All simulations were run with $\alpha =0.001$ and mini-batch size $4$.\\ \leavevmode {\color {Aquamarine}\textbf {[Dani: Change tanh-results-bs=16-lr=0\_001-s1000.pdf to tanh-results-bs=\leavevmode {\color {red}4}-lr=0\_001-s1000.pdf]}}\\ \leavevmode {\color {Aquamarine}\textbf {[Dani: increase tick size on inference plots]}} }}{24}{figure.10}%
\select@language {english} \contentsline {figure}{\numberline {11}{\ignorespaces (a) Visual representation of a sparse Hamiltonian matrix $H_{jj'}$ for a Bose-Hubbard model with $\qopname \relax o{dim}(\mathcal H)=35$. Darker points show the non-zero elements in the matrix (b) Numerical solutions of the ground-state energy for different $U$ and $t$ values.}}{26}{figure.11}%
\select@language {english} \contentsline {figure}{\numberline {12}{\ignorespaces Illustration of a variational ansatz circuit with its first layer. Initially, each of the four qumodes contain a single photon. The layer is built up from Kerr-gates, CrossKerr gates and Beamsplitters, which are passive optical gates, so the total number of photons is preserved.}}{26}{figure.12}%
\select@language {english} \contentsline {figure}{\numberline {13}{\ignorespaces }}{27}{figure.13}%
\select@language {english} \contentsline {figure}{\numberline {14}{\ignorespaces caption}}{28}{figure.14}%
